{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:18.088250Z",
     "start_time": "2019-05-23T04:51:17.426066Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of word model for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:21.661953Z",
     "start_time": "2019-05-23T04:51:21.658143Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    ! wget http://www.cs.cornell.edu/people/pabo/movie-review-data/rotten_imdb.tar.gz\n",
    "    ! mkdir data\n",
    "    ! tar -xvf rotten_imdb.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:22.437635Z",
     "start_time": "2019-05-23T04:51:22.287902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-20 13:01:57--  http://www.cs.cornell.edu/people/pabo/movie-review-data/rotten_imdb.tar.gz\n",
      "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.20\n",
      "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.20|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 519599 (507K) [application/x-gzip]\n",
      "Saving to: ‘rotten_imdb.tar.gz’\n",
      "\n",
      "rotten_imdb.tar.gz  100%[===================>] 507.42K   539KB/s    in 0.9s    \n",
      "\n",
      "2020-06-20 13:01:58 (539 KB/s) - ‘rotten_imdb.tar.gz’ saved [519599/519599]\n",
      "\n",
      "x quote.tok.gt9.5000\n",
      "x plot.tok.gt9.5000\n",
      "x subjdata.README.1.0\n",
      "plot.tok.gt9.5000   quote.tok.gt9.5000  subjdata.README.1.0\n"
     ]
    }
   ],
   "source": [
    "get_data()\n",
    "! ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    \"\"\" Read file returns a list of lines.\n",
    "    \"\"\"\n",
    "    with open(path, encoding = \"ISO-8859-1\") as f:\n",
    "        content = f.readlines()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:31.979291Z",
     "start_time": "2019-05-23T04:51:30.952129Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_content = read_file(\"data/quote.tok.gt9.5000\")\n",
    "obj_content = read_file(\"data/plot.tok.gt9.5000\")\n",
    "sub_content = np.array([line.strip().lower() for line in sub_content])\n",
    "obj_content = np.array([line.strip().lower() for line in obj_content])\n",
    "sub_y = np.zeros(len(sub_content))\n",
    "obj_y = np.ones(len(obj_content))\n",
    "X = np.append(sub_content, obj_content)\n",
    "y = np.append(sub_y, obj_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:31.992431Z",
     "start_time": "2019-05-23T04:51:31.982777Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000,), (8000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:38.938607Z",
     "start_time": "2019-05-23T04:51:38.935347Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:40.729422Z",
     "start_time": "2019-05-23T04:51:40.615629Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vocab(content):\n",
    "    \"\"\"Computes Dict of counts of words.\n",
    "    \n",
    "    Computes the number of times a word is on a document.\n",
    "    \"\"\"\n",
    "    vocab = defaultdict(float)\n",
    "    for line in content:\n",
    "        words = set(line.split())\n",
    "        for word in words:\n",
    "            vocab[word] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = get_vocab(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:42.018188Z",
     "start_time": "2019-05-23T04:51:42.007413Z"
    }
   },
   "outputs": [],
   "source": [
    "for word in list(word_count):\n",
    "    if word_count[word] < 5:\n",
    "        del word_count[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:42.328623Z",
     "start_time": "2019-05-23T04:51:42.320719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4008"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"UNK\":0} # init with unknown\n",
    "words = [\"UNK\"]\n",
    "for word in word_count:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of word representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:51:44.007326Z",
     "start_time": "2019-05-23T04:51:44.000065Z"
    }
   },
   "outputs": [],
   "source": [
    "def bow(x, vocab2index):\n",
    "    enc = np.zeros(len(vocab2index.keys()))\n",
    "    words = set(x.split())\n",
    "    for word in words:\n",
    "        enc[vocab2index.get(word, 0)] = 1 # 0 if the UNK index\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"both lead performances are oscar-size . quaid is utterly fearless as the tortured husband living a painful lie , and moore wonderfully underplays the long-suffering heroine with an unflappable '50s dignity somewhere between jane wyman and june cleaver .\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., ..., 0., 0., 0.]), (4009,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = bow(x_train[0], vocab2index)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:52:54.922573Z",
     "start_time": "2019-05-23T04:52:54.916113Z"
    }
   },
   "outputs": [],
   "source": [
    "class BOW(Dataset):\n",
    "    def __init__(self, x, y, vocab2index):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.vocab2index = vocab2index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        x = bow(x, self.vocab2index)\n",
    "        return x, self.y[idx, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:53:03.828040Z",
     "start_time": "2019-05-23T04:53:03.824699Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = BOW(x_train, y_train, vocab2index)\n",
    "val_ds = BOW(x_val, y_val, vocab2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:53:42.310065Z",
     "start_time": "2019-05-23T04:53:42.306412Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=1000, shuffle=True)\n",
    "valid_dl = DataLoader(val_ds, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 4009]), torch.Size([1000, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_dl))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation accuracy\n",
    "\n",
    "Two ways of defining a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab2index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(valid_dl))\n",
    "x = x.float()\n",
    "y = y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:55:57.455475Z",
     "start_time": "2019-05-23T04:55:57.449408Z"
    }
   },
   "outputs": [],
   "source": [
    "class BOWModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(BOWModel, self).__init__()\n",
    "        self.linear = nn.Linear(vocab_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BOWModel(vocab_size=len(vocab2index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T04:56:29.431871Z",
     "start_time": "2019-05-23T04:56:29.426088Z"
    }
   },
   "outputs": [],
   "source": [
    "def val_metrics(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_sum = 0\n",
    "    for x, y in valid_dl:\n",
    "        y_hat = model(x.float())\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y.float())\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y.float()).float().sum()\n",
    "        total += x.size(0)\n",
    "        loss_sum += loss.item()*x.size(0)\n",
    "    accuracy = correct.item()/total\n",
    "    return loss_sum/total, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T09:04:45.628616Z",
     "start_time": "2019-05-22T09:04:45.574265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6922248601913452, 0.494)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T09:04:48.131508Z",
     "start_time": "2019-05-22T09:04:48.124575Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        loss_sum = 0\n",
    "        for x, y in train_dl:\n",
    "            y_hat = model(x.float())\n",
    "            loss = F.binary_cross_entropy_with_logits(y_hat, y.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += x.size(0)\n",
    "            loss_sum += loss.item()*x.size(0)\n",
    "        val_loss, val_acc = val_metrics(model)\n",
    "        print(\"train loss %.3f val loss %.3f and accuracy %.3f\" % (loss_sum/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-22T09:05:03.287290Z",
     "start_time": "2019-05-22T09:04:54.494282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.660 val loss 0.619 and accuracy 0.875\n",
      "train loss 0.579 val loss 0.555 and accuracy 0.885\n",
      "train loss 0.515 val loss 0.504 and accuracy 0.896\n",
      "train loss 0.464 val loss 0.464 and accuracy 0.899\n",
      "train loss 0.424 val loss 0.431 and accuracy 0.896\n",
      "train loss 0.392 val loss 0.406 and accuracy 0.900\n",
      "train loss 0.365 val loss 0.385 and accuracy 0.902\n",
      "train loss 0.344 val loss 0.368 and accuracy 0.904\n",
      "train loss 0.325 val loss 0.353 and accuracy 0.903\n",
      "train loss 0.309 val loss 0.341 and accuracy 0.906\n",
      "train loss 0.296 val loss 0.330 and accuracy 0.907\n",
      "train loss 0.283 val loss 0.321 and accuracy 0.909\n",
      "train loss 0.272 val loss 0.313 and accuracy 0.909\n",
      "train loss 0.263 val loss 0.306 and accuracy 0.909\n",
      "train loss 0.254 val loss 0.300 and accuracy 0.910\n"
     ]
    }
   ],
   "source": [
    "model = BOWModel(vocab_size=len(vocab2index.keys()))\n",
    "train_epocs(model, 15, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word importance\n",
    "To get the words that affect the most the positive label we find the words with higher weights. Similarly to get the words that affect the most the 0 label we find the words with lower weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1923,  0.1539, -0.3411,  ..., -0.2199,  0.2210,  0.2873]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-0.0330], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms = [p for p in model.parameters()]\n",
    "parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19232845,  0.15388994, -0.34107742, ..., -0.21992844,\n",
       "         0.22099222,  0.28726828]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = parms[0].detach().numpy()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4009,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indeces = np.argsort(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4617616, 0.4669453)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0, sorted_indeces[0]], weights[0, sorted_indeces[-1]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['performance',\n",
       " 'material',\n",
       " 'performances',\n",
       " 'fascinating',\n",
       " 'actors',\n",
       " 'beautifully',\n",
       " 'screen',\n",
       " 'melodrama',\n",
       " 'movie',\n",
       " 'audience']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[words[i] for i in sorted_indeces[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learns',\n",
       " 'realize',\n",
       " 'him',\n",
       " 'school',\n",
       " 'known',\n",
       " 'secret',\n",
       " 'relationship',\n",
       " '-',\n",
       " 'they',\n",
       " 'however',\n",
       " 'discover']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[words[i] for i in sorted_indeces[3998:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
